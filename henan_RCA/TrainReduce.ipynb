{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "sys.setrecursionlimit(100000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "warnings.filterwarnings('ignore')           #不显示警告\n",
    "print(\"导入包完成！\")\n",
    "st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1、读取数据\n",
    "Dir = '/root/AI告警分析数据/告警'\n",
    "File = os.path.join(Dir, 'alarm_20190914.csv')\n",
    "df = pd.read_csv(File, sep='^')\n",
    "print(\"完成数据加载！\")\n",
    "print(\"原始数据维度\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2、查看对应字段和数据\n",
    "df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3、去除4级告警对算法模型的干扰\n",
    "df = df[df['网管告警级别']!=4].copy()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"滤除4级告警后的数据维度为\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3、根据业务经验，过滤衍生告警和未匹配告警\n",
    "df = df[df['告警标题'].apply(lambda x:np.nan if '衍生' in str(x) else x).notnull()].copy()\n",
    "df = df[df['告警标题']!='未匹配告警'].copy()\n",
    "print(\"滤除衍生告警后的数据维度为\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4、加载补充信息表，如厂家ID与厂家名的映射关系，厂家名与厂家告警ID的映射关系，网元名称与网元ID的映射关系\n",
    "\n",
    "#厂家ID与厂家名的映射关系\n",
    "vendor_ring = pd.read_csv('/root/AI告警分析数据/ring_vendor_id_name.csv',sep='\\t')\n",
    "vendor_ring.rename(columns={'device_id':'厂家ID'}, inplace=True)\n",
    "vendor_ring.drop_duplicates('厂家ID', inplace=True)\n",
    "vendor_ring['厂家ID'] = vendor_ring['厂家ID'].apply(lambda x:np.nan if '-' in x else int(x))\n",
    "\n",
    "#厂家ID与厂家名的映射关系\n",
    "vendor_nring = pd.read_csv('/root/AI告警分析数据/notring_vendoer_id_name.csv',sep='\\t')\n",
    "vendor_nring.rename(columns={'device_id':'厂家ID'}, inplace=True)\n",
    "vendor_nring.drop_duplicates('厂家ID', inplace=True)\n",
    "\n",
    "#网元名称与网元ID的映射关系\n",
    "device_id_name = pd.read_csv('/root/AI告警分析数据/device_id_type.csv',sep='\\t')\n",
    "\n",
    "#厂家名与厂家告警ID的映射关系\n",
    "version = pd.read_csv('/root/codes/RCA/alarm_norm_file/version.csv')\n",
    "version.rename(columns={'网管告警ID':'alarmid_sup'}, inplace=True)\n",
    "version.dropna(subset=['厂家'], inplace=True)\n",
    "version.drop_duplicates(subset=['厂家', '厂家告警ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5、拼接设备类型名称\n",
    "print(\"网管告警ID缺失数据条数\",df['网管告警ID'].isnull().sum())\n",
    "data = df.merge(device_id_name, on=['设备类型ID'], how='left')\n",
    "\n",
    "#切分动环和非动环数据\n",
    "df_nr = data[data['专业ID']!=8].copy()\n",
    "df_r = data[data['专业ID']==8].copy()\n",
    "\n",
    "#拼接厂家设备名\n",
    "df_nr = df_nr.merge(vendor_nring, on=['厂家ID'], how='left')\n",
    "df_r = df_r.merge(vendor_ring, on=['厂家ID'], how='left')\n",
    "data = pd.concat([df_nr, df_r], axis=0)\n",
    "data.rename(columns={'device_name':'厂家'}, inplace=True)\n",
    "data['厂家'] = data['厂家'].apply(lambda x:'摩托罗拉' if '摩托罗拉' in str(x) else x)\n",
    "print(data.shape)\n",
    "\n",
    "#拼接厂家告警ID,只填充少数网管告警ID\n",
    "data  = data.merge(version[['厂家', '厂家告警ID', 'alarmid_sup']], on=['厂家', '厂家告警ID'], how='left')\n",
    "data.loc[data['网管告警ID'].isnull(), '网管告警ID'] = data[data['网管告警ID'].isnull()]['alarmid_sup']\n",
    "print(\"网管告警ID仍然缺失数据条数\",data['网管告警ID'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6、转换标准时间为时间戳，用于密度聚类\n",
    "data['timestamp'] = pd.to_datetime(data['发生时间'])\n",
    "data['timestamp'] = pd.to_timedelta(data.timestamp).dt.total_seconds()\n",
    "data.sort_values(by=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7、逐地市对告警信息进行根因分析，首先对不同地市采取聚类，基本划分为5-10分钟为一段周期，根据先前模型训练得到的规则表，对其进行告警压缩\n",
    "RemoveSlave = []\n",
    "#参数集\n",
    "city_eps_ms = {\n",
    " 2000:(5,1), 2001:(11,1), 2002:(6,1), 2003:(11,1), 2004:(7,1), 2005:(5,1), 2006:(14,1),\n",
    " 2007:(11,1), 2008:(5,1), 2009:(11,1), 2010:(11,1), 2011:(3,1), 2012:(10,1), 2013:(8,1)\n",
    "}\n",
    "\n",
    "for city, (eps, ms) in city_eps_ms.items():\n",
    "    #7.1、采用DBSCAN聚类划分时域\n",
    "    train = data.query('地市ID==%d'%city).copy()\n",
    "    features = train[['timestamp']].values\n",
    "    clustering = DBSCAN(eps=eps, min_samples=ms).fit(features)#labal=251\n",
    "    labels = clustering.labels_\n",
    "    num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    print('Estimated number of clusters: %d' % num_clusters)\n",
    "    print('Estimated number of noise points: %d' % n_noise)\n",
    "    print(\"完成聚类！\")\n",
    "    train['label'] = labels\n",
    "\n",
    "    #7.2、滤除异常点\n",
    "    train = train[train['label'] != -1]\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    print(\"训练数据维度\", train.shape)\n",
    "    #选取与规则字段对应的数据，用于后续分析\n",
    "    cols1 = ['专业ID', '告警标题', '网管告警级别',  '网元名称', '厂家', '设备类型名称', '地市ID', 'timestamp', '网管告警ID', \n",
    "              '是否与对端网元相关', '该事件对业务的影响','label','发生时间','清除时间']\n",
    "    cols2 = ['specialtyid', 'alarm_title', 'alarm_level', 'deveice_name', 'vendor', 'device_type_name', 'city', 'timestamp', \n",
    "                     'alarm_id', 'isvendorcor', 'isinfluence', 'label','starttime','cleartiem']\n",
    "    rename_map = dict(zip(cols1, cols2))\n",
    "    train = train.rename(columns=rename_map)\n",
    "    \n",
    "    specialty_dict = {1:'无线',2:'核心网',6:'传输',8:'动环'}\n",
    "    train['specialty'] = train['specialtyid'].map(specialty_dict)\n",
    "    train.groupby(['specialty']).size()\n",
    "    \n",
    "    #pair_id\n",
    "    train['pair_id'] = train['alarm_title'] + '_' + train['deveice_name']\n",
    "    \n",
    "    #7.3、读取湖南数据生成的规则表，进行告警压缩\n",
    "    # HisRules = pd.read_csv('MSNe_Rules.csv')\n",
    "    HisRules = pd.read_csv('/root/AI告警分析数据/batch/MSNe_Rules.csv')\n",
    "    MasterId = set(HisRules['master_title'].values)\n",
    "    SlaveId = set(HisRules['slave_title'].values)\n",
    "    MasterSlaveAlarm = dict(HisRules.groupby('slave_title').agg({'master_title':'unique'}).reset_index().values)\n",
    "    MasterSlaveAlarm = {key:set(values) for key, values in MasterSlaveAlarm.items()}\n",
    "\n",
    "    for idx, group in train.groupby('label'):\n",
    "        MasterTmp = set(group['alarm_title'].values)&MasterId\n",
    "        SlaveTmp = set(group['alarm_title'].values)&SlaveId\n",
    "        if MasterTmp and SlaveTmp:\n",
    "            for slave_id in SlaveTmp:\n",
    "                if len(MasterTmp&MasterSlaveAlarm[slave_id])>=1:\n",
    "                    RemoveSlave.append(slave_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8、输出告警压缩和去重的数据\n",
    "RemoveSlavedf = pd.DataFrame(list(set(RemoveSlave)), columns=['告警标题'])\n",
    "RemoveSlavedf['IsRemove'] = 1\n",
    "RM_data = data.merge(RemoveSlavedf, on='告警标题', how='left')\n",
    "RM_data = RM_data.query('IsRemove!=1').copy()\n",
    "print('压缩后数据维度',RM_data.shape)\n",
    "RM_data.drop_duplicates(['告警标题','网元名称'], inplace=True)\n",
    "print('去重后后数据维度',RM_data.shape)\n",
    "print(\"完成第一轮的告警压缩！\")\n",
    "print(\"压缩率为：\", 1-RM_data.shape[0]/data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9、去除三级告警\n",
    "print(\"去除三级告警后数据维度\",RM_data[RM_data['网管告警级别']!=3].shape)\n",
    "RM_data = RM_data[RM_data['网管告警级别']!=3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10、去除发生时间与清楚时间相隔一分钟内的数据\n",
    "RM_data['starttime'] = pd.to_datetime(RM_data['发生时间'])\n",
    "RM_data['starttime'] = pd.to_timedelta(RM_data.starttime).dt.total_seconds()\n",
    "RM_data.sort_values(by=['starttime'], inplace=True)\n",
    "\n",
    "RM_data['endtime'] = pd.to_datetime(RM_data['清除时间'])\n",
    "RM_data['endtime'] = pd.to_timedelta(RM_data.endtime).dt.total_seconds()\n",
    "RM_data.sort_values(by=['endtime'], inplace=True)\n",
    "\n",
    "RM_data['delttime'] = RM_data['endtime'] - RM_data['starttime']\n",
    "\n",
    "print(\"告警发生与清除时间差大于1分钟的数据维度\", RM_data[RM_data['delttime']>60].shape)\n",
    "RM_data = RM_data[RM_data['delttime']>60].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11、去除去除编码非标准化的告警数据\n",
    "print(\"去除编码非标准化的告警信息\", RM_data['网管告警ID'].notnull().sum())\n",
    "RM_data = RM_data[RM_data['网管告警ID'].notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"完成告警压缩总时间\", (time.time()-st)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_data[['告警标题','网元名称']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
